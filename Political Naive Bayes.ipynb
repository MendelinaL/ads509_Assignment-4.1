{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes on Political Text - Mendelina Lopez\n",
    "\n",
    "In this notebook we use Naive Bayes to explore and classify political data. See the `README.md` for full details. You can download the required DB from the shared dropbox or from blackboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mendi\\Anaconda3\\lib\\site-packages\\pandas\\compat\\_optional.py:138: UserWarning: Pandas requires version '2.7.0' or newer of 'numexpr' (version '2.6.9' currently installed).\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import nltk\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from ast import literal_eval\n",
    "\n",
    "# Feel free to include your text patterns functions\n",
    "#from text_functions_solutions import clean_tokenize, get_patterns\n",
    "\n",
    "# Some punctuation variations\n",
    "punctuation = set(punctuation) # speeds up comparison\n",
    "tw_punct = punctuation - {\"#\"}\n",
    "\n",
    "# Stopwords\n",
    "sw = stopwords.words(\"english\")\n",
    "\n",
    "\n",
    "def remove_punctuation(text, punct_set=tw_punct) : \n",
    "    return(\"\".join([ch for ch in text if ch not in punct_set]))\n",
    "\n",
    "def tokenize(text) : \n",
    "    return(word_tokenize(text))\n",
    "\n",
    "def prepare(text, pipeline) : \n",
    "    tokens = str(text)\n",
    "    \n",
    "    for transform in pipeline : \n",
    "        tokens = transform(tokens)\n",
    "        \n",
    "    return(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('conventions',)]\n"
     ]
    }
   ],
   "source": [
    "convention_db = sqlite3.connect(\"2020_Conventions.db\")\n",
    "convention_cur = convention_db.cursor()\n",
    "\n",
    "# I would like to see if there are other tables\n",
    "convention_cur.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "print(convention_cur.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "party\n",
      "night\n",
      "speaker\n",
      "speaker_count\n",
      "time\n",
      "text\n",
      "text_len\n",
      "file\n"
     ]
    }
   ],
   "source": [
    "# I would like to view the columns within the table\n",
    "data = convention_cur.execute('''SELECT * FROM conventions''')\n",
    "for column in data.description:\n",
    "    print(column[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Exploratory Naive Bayes\n",
    "\n",
    "We'll first build a NB model on the convention data itself, as a way to understand what words distinguish between the two parties. This is analogous to what we did in the \"Comparing Groups\" class work. First, pull in the text \n",
    "for each party and prepare it for use in Naive Bayes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_pipeline = [str.lower, remove_punctuation, tokenize]\n",
    "convention_data = []\n",
    "\n",
    "# fill this list up with items that are themselves lists. The \n",
    "# first element in the sublist should be the cleaned and tokenized\n",
    "# text in a single string. The second element should be the party. \n",
    "\n",
    "query_results = convention_cur.execute(\n",
    "                            '''\n",
    "                            SELECT text, party FROM conventions\n",
    "                            WHERE speaker != \"Unknown\"\n",
    "                            ''')\n",
    "\n",
    "for row in query_results :\n",
    "    # store the results in convention_data\n",
    "    text = \" \".join(prepare(row[0],pipeline=my_pipeline))\n",
    "    if text :\n",
    "        convention_data.append([\" \".join(prepare(row[0],pipeline=my_pipeline)),row[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some random entries and see if they look right. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['it will be led by joe biden and it ’ s aimed at ending the disease that killed the vice president ’ s son and 600000 other americans every year',\n",
       "  'Democratic'],\n",
       " ['the first thing a president needs to do is find out what the facts are this president doesn ’ t care about facts tom c 015523 biden cares about the safety and welfare of american servicemen and women',\n",
       "  'Democratic'],\n",
       " ['as the next', 'Democratic'],\n",
       " ['and finally joe biden will officially accept the nomination for president i ’ ll be tuning in i hope you will too thank you for letting me be a part of your night',\n",
       "  'Democratic'],\n",
       " ['but what are the consequences when only one side of the story gets out or when only one viewpoint is acceptable for our education system it meant sacrificing civil debate by creating an atmosphere where students with contrary opinions are too afraid to speak many students find themselves suppressing their beliefs to fit into what the acceptable groupthink is in short our nation suffers by inhibiting our diversity of thought and inclusion of ideas working together outside of our political comfort zones we ’ ll accomplish so much more some cynical politicians do not seem to believe in the miracle of america well i do as maximo alvarez said so eloquently last night “ if freedom is lost in this country there is nowhere else to go ” having hope is not weakness and believing in miracles is a gift from god',\n",
       "  'Republican'],\n",
       " ['excuse me mommy', 'Democratic'],\n",
       " ['generally speaking as a church you ’ re concerned about people spiritually but you ’ re also concerned about other areas of their life and that includes their physical or physiological wellbeing because the bible talks about all of us but there are people in our country and in fact people in my church that can ’ t take advantage of it because they don ’ t have good healthcare that ’ s definitely discouraging to me and that ’ s pretty discouraging to them',\n",
       "  'Democratic'],\n",
       " ['louisiana', 'Democratic'],\n",
       " ['enough is enough it ’ s time to help small businesses middle class folks manage their way through a pandemic',\n",
       "  'Democratic'],\n",
       " ['growing up it was full of adventure laughter', 'Democratic']]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choices(convention_data,k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If that looks good, we now need to make our function to turn these into features. In my solution, I wanted to keep the number of features reasonable, so I only used words that occur at least `word_cutoff` times. Here's the code to test that if you want it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a word cutoff of 5, we have 2441 as features in the model.\n"
     ]
    }
   ],
   "source": [
    "word_cutoff = 5\n",
    "\n",
    "tokens = [w for t, p in convention_data for w in t.split()]\n",
    "\n",
    "word_dist = nltk.FreqDist(tokens)\n",
    "\n",
    "feature_words = set()\n",
    "\n",
    "for word, count in word_dist.items() :\n",
    "    if count > word_cutoff :\n",
    "        feature_words.add(word)\n",
    "        \n",
    "print(f\"With a word cutoff of {word_cutoff}, we have {len(feature_words)} as features in the model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_features(text,fw = feature_words) :\n",
    "    \"\"\"Given some text, this returns a dictionary holding the\n",
    "       feature words.\n",
    "       \n",
    "       Args: \n",
    "            * text: a piece of text in a continuous string. Assumes\n",
    "            text has been cleaned and case folded.\n",
    "            * fw: the *feature words* that we're considering. A word \n",
    "            in `text` must be in fw in order to be returned. This \n",
    "            prevents us from considering very rarely occurring words.\n",
    "        \n",
    "       Returns: \n",
    "            A dictionary with the words in `text` that appear in `fw`. \n",
    "            Words are only counted once. \n",
    "            If `text` were \"quick quick brown fox\" and `fw` = {'quick','fox','jumps'},\n",
    "            then this would return a dictionary of \n",
    "            {'quick' : True,\n",
    "             'fox' :    True}\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    text_tokens = text.split()\n",
    "    text_feat_words = [ch for ch in text_tokens if ch in fw]\n",
    "    \n",
    "    \n",
    "    ret_dict = dict.fromkeys(text_feat_words, True)\n",
    "    \n",
    "    return(ret_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-be3e6a1914ee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32massert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m assert(conv_features(\"donald is the president\",feature_words)==\n\u001b[1;32m----> 3\u001b[1;33m        {'donald':True,'president':True})\n\u001b[0m\u001b[0;32m      4\u001b[0m assert(conv_features(\"people are american in america\",feature_words)==\n\u001b[0;32m      5\u001b[0m                      {'america':True,'american':True,\"people\":True})\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert(len(feature_words)>0)\n",
    "assert(conv_features(\"donald is the president\",feature_words)==\n",
    "       {'donald':True,'president':True})\n",
    "assert(conv_features(\"people are american in america\",feature_words)==\n",
    "                     {'america':True,'american':True,\"people\":True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll build our feature set. Out of curiosity I did a train/test split to see how accurate the classifier was, but we don't strictly need to since this analysis is exploratory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(conv_features(text,feature_words), party) for (text, party) in convention_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(20220507)\n",
    "random.shuffle(featuresets)\n",
    "\n",
    "test_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.448\n"
     ]
    }
   ],
   "source": [
    "test_set, train_set = featuresets[:test_size], featuresets[test_size:]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                 radical = True           Republ : Democr =     38.0 : 1.0\n",
      "                   media = True           Republ : Democr =     38.0 : 1.0\n",
      "                   votes = True           Democr : Republ =     22.8 : 1.0\n",
      "             enforcement = True           Republ : Democr =     18.4 : 1.0\n",
      "                   crime = True           Republ : Democr =     17.2 : 1.0\n",
      "                   china = True           Republ : Democr =     16.3 : 1.0\n",
      "                 destroy = True           Republ : Democr =     16.2 : 1.0\n",
      "                freedoms = True           Republ : Democr =     16.2 : 1.0\n",
      "                  defund = True           Republ : Democr =     14.1 : 1.0\n",
      "                  earned = True           Republ : Democr =     14.1 : 1.0\n",
      "                  lowest = True           Republ : Democr =     13.0 : 1.0\n",
      "              prosperity = True           Republ : Democr =     13.0 : 1.0\n",
      "                   taxes = True           Republ : Democr =     12.8 : 1.0\n",
      "                    mike = True           Republ : Democr =     12.2 : 1.0\n",
      "                religion = True           Republ : Democr =     12.0 : 1.0\n",
      "                 beliefs = True           Republ : Democr =     12.0 : 1.0\n",
      "                 violent = True           Republ : Democr =     12.0 : 1.0\n",
      "                      50 = True           Republ : Democr =     11.6 : 1.0\n",
      "                 african = True           Republ : Democr =     10.9 : 1.0\n",
      "                received = True           Republ : Democr =     10.9 : 1.0\n",
      "                 climate = True           Democr : Republ =     10.9 : 1.0\n",
      "                  record = True           Republ : Democr =     10.0 : 1.0\n",
      "                    seem = True           Republ : Democr =      9.9 : 1.0\n",
      "                   enemy = True           Republ : Democr =      9.9 : 1.0\n",
      "               countries = True           Republ : Democr =      9.9 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a little prose here about what you see in the classifier. Anything odd or interesting?\n",
    "\n",
    "### My Observations\n",
    "\n",
    "I find it interesting that 'radical' is at the top of the list. I am not surprised that 'media' is next on the list. Media plays a major role in politics, especially within recent years. It seems like there is such a jump in differences between the first two words' scores compared to the rest.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Classifying Congressional Tweets\n",
    "\n",
    "In this part we apply the classifer we just built to a set of tweets by people running for congress\n",
    "in 2018. These tweets are stored in the database `congressional_data.db`. That DB is funky, so I'll\n",
    "give you the query I used to pull out the tweets. Note that this DB has some big tables and \n",
    "is unindexed, so the query takes a minute or two to run on my machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cong_db = sqlite3.connect(\"congressional_data.db\")\n",
    "cong_cur = cong_db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('websites',), ('candidate_data',), ('tweets',)]\n"
     ]
    }
   ],
   "source": [
    "cong_cur.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "print(cong_cur.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cong_cur.execute(\n",
    "        '''\n",
    "           SELECT DISTINCT \n",
    "                  cd.candidate, \n",
    "                  cd.party,\n",
    "                  tw.tweet_text\n",
    "           FROM candidate_data cd \n",
    "           INNER JOIN tweets tw ON cd.twitter_handle = tw.handle \n",
    "               AND cd.candidate == tw.candidate \n",
    "               AND cd.district == tw.district\n",
    "           WHERE cd.party in ('Republican','Democratic') \n",
    "               AND tw.tweet_text NOT LIKE '%RT%'\n",
    "        ''')\n",
    "\n",
    "results = list(results) # Just to store it, since the query is time consuming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data = []\n",
    "\n",
    "# Now fill up tweet_data with sublists like we did on the convention speeches.\n",
    "# Note that this may take a bit of time, since we have a lot of tweets.\n",
    "for rowt in results :\n",
    "    # store the results in convention_data\n",
    "    textt = \" \".join(prepare(rowt[2],pipeline=my_pipeline))\n",
    "    if textt :\n",
    "        tweet_data.append([rowt[1],\" \".join(prepare(rowt[2],pipeline=my_pipeline))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of tweets here. Let's take a random sample and see how our classifer does. I'm guessing it won't be too great given the performance on the convention speeches..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Democratic',\n",
       "  'bearlier today i spoke on the house floor abt protecting health care for women and praised ppmarmonte for their work on the central coast httpstcowqgtrzt7vv'],\n",
       " ['Democratic', 'bgo tribe # rallytogether httpstco0nxutfl9l5'],\n",
       " ['Democratic',\n",
       "  'bapparently trump thinks its just too easy for students overwhelmed by the crushing burden of debt to pay off student loans # trumpbudget httpstcockyqo5t0qh'],\n",
       " ['Republican',\n",
       "  'bwexe2x80x99re grateful for our first responders our rescue personnel our firefighters our police and volunteers who have been working tirelessly to keep people safe provide muchneeded help while putting their own lives on the linennhttpstcoezpv0vmiz3'],\n",
       " ['Republican',\n",
       "  'bletxe2x80x99s make it even greater # kag xf0x9fx87xbaxf0x9fx87xb8 httpstcoy9qozd5l2z'],\n",
       " ['Democratic',\n",
       "  'bwe have about 1hr until the cavs tie up the series 22 im # allin216 repbarbaralee you scared # roadtovictory'],\n",
       " ['Democratic',\n",
       "  'bcongrats to belliottsd on his new gig at sd city hall we are glad you will continue to servexe2x80xa6 httpstcofkvmw3cqdi'],\n",
       " ['Democratic',\n",
       "  'bwe are really close we have over 3500 raised toward the match right now whoot thatxe2x80x99s 7000 for the nonmath majors in the room xf0x9fx98x82 help us get there httpstcotu34c472sd httpstcoqsdqkypsmc'],\n",
       " ['Democratic',\n",
       "  'btoday the comment period for potusxe2x80x99s plan to expand offshore drilling opened to the public you have 60 days until march 9 to share why you oppose the proposed program directly with the trump administration comments can be made by email or mail httpstcobaaymejxqn'],\n",
       " ['Democratic',\n",
       "  'bcelebrated icseastlaxe2x80x99s 22 years of eastside commitment amp saluted community leaders at last nightxe2x80x99s awards dinner httpstco7v7gh8givb']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(20201014)\n",
    "\n",
    "tweet_data_sample = random.choices(tweet_data,k=10)\n",
    "tweet_data_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's our (cleaned) tweet: bearlier today i spoke on the house floor abt protecting health care for women and praised ppmarmonte for their work on the central coast httpstcowqgtrzt7vv\n",
      "Actual party is Democratic and our classifer says ['Democratic'].\n",
      "\n",
      "Here's our (cleaned) tweet: bgo tribe # rallytogether httpstco0nxutfl9l5\n",
      "Actual party is Democratic and our classifer says ['bgo tribe # rallytogether httpstco0nxutfl9l5'].\n",
      "\n",
      "Here's our (cleaned) tweet: bapparently trump thinks its just too easy for students overwhelmed by the crushing burden of debt to pay off student loans # trumpbudget httpstcockyqo5t0qh\n",
      "Actual party is Democratic and our classifer says ['bgo tribe # rallytogether httpstco0nxutfl9l5'].\n",
      "\n",
      "Here's our (cleaned) tweet: bwexe2x80x99re grateful for our first responders our rescue personnel our firefighters our police and volunteers who have been working tirelessly to keep people safe provide muchneeded help while putting their own lives on the linennhttpstcoezpv0vmiz3\n",
      "Actual party is Republican and our classifer says ['bgo tribe # rallytogether httpstco0nxutfl9l5'].\n",
      "\n",
      "Here's our (cleaned) tweet: bletxe2x80x99s make it even greater # kag xf0x9fx87xbaxf0x9fx87xb8 httpstcoy9qozd5l2z\n",
      "Actual party is Republican and our classifer says ['Democratic'].\n",
      "\n",
      "Here's our (cleaned) tweet: bwe have about 1hr until the cavs tie up the series 22 im # allin216 repbarbaralee you scared # roadtovictory\n",
      "Actual party is Democratic and our classifer says ['Democratic'].\n",
      "\n",
      "Here's our (cleaned) tweet: bcongrats to belliottsd on his new gig at sd city hall we are glad you will continue to servexe2x80xa6 httpstcofkvmw3cqdi\n",
      "Actual party is Democratic and our classifer says ['Democratic'].\n",
      "\n",
      "Here's our (cleaned) tweet: bwe are really close we have over 3500 raised toward the match right now whoot thatxe2x80x99s 7000 for the nonmath majors in the room xf0x9fx98x82 help us get there httpstcotu34c472sd httpstcoqsdqkypsmc\n",
      "Actual party is Democratic and our classifer says ['bgo tribe # rallytogether httpstco0nxutfl9l5'].\n",
      "\n",
      "Here's our (cleaned) tweet: btoday the comment period for potusxe2x80x99s plan to expand offshore drilling opened to the public you have 60 days until march 9 to share why you oppose the proposed program directly with the trump administration comments can be made by email or mail httpstcobaaymejxqn\n",
      "Actual party is Democratic and our classifer says ['Democratic'].\n",
      "\n",
      "Here's our (cleaned) tweet: bcelebrated icseastlaxe2x80x99s 22 years of eastside commitment amp saluted community leaders at last nightxe2x80x99s awards dinner httpstco7v7gh8givb\n",
      "Actual party is Democratic and our classifer says ['bgo tribe # rallytogether httpstco0nxutfl9l5'].\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for party, tweet in tweet_data_sample :\n",
    "    estimated_party = random.choices(tweet_data_sample[1],k=1)\n",
    "    # Fill in the right-hand side above with code that estimates the actual party\n",
    "    \n",
    "    print(f\"Here's our (cleaned) tweet: {tweet}\")\n",
    "    print(f\"Actual party is {party} and our classifer says {estimated_party}.\")\n",
    "    print(\"\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've looked at it some, let's score a bunch and see how we're doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-dc4b5db877c4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mestimated_party\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweet_data_sample\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mparty\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mestimated_party\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mnum_to_score\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "# dictionary of counts by actual party and estimated party. \n",
    "# first key is actual, second is estimated\n",
    "parties = ['Republican','Democratic']\n",
    "results = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for p in parties :\n",
    "    for p1 in parties :\n",
    "        results[p][p1] = 0\n",
    "\n",
    "\n",
    "num_to_score = 10000\n",
    "random.shuffle(tweet_data)\n",
    "\n",
    "for idx, tp in enumerate(tweet_data) :\n",
    "    party, tweet = tp    \n",
    "    # Now do the same thing as above, but we store the results rather\n",
    "    # than printing them. \n",
    "   \n",
    "    # get the estimated party\n",
    "    estimated_party = random.choices(tweet_data_sample[1],k=1)\n",
    "    \n",
    "    results[party][estimated_party] += 1\n",
    "    \n",
    "    if idx > num_to_score : \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflections\n",
    "\n",
    "_Write a little about what you see in the results_ "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
